{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install supabase\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aOFtTPjeZeNf",
        "outputId": "a7118ecf-b012-4d06-9add-85942be9ba65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting supabase\n",
            "  Downloading supabase-2.13.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting gotrue<3.0.0,>=2.11.0 (from supabase)\n",
            "  Downloading gotrue-2.11.4-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: httpx<0.29,>=0.26 in /usr/local/lib/python3.11/dist-packages (from supabase) (0.28.1)\n",
            "Collecting postgrest<0.20,>=0.19 (from supabase)\n",
            "  Downloading postgrest-0.19.3-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting realtime<3.0.0,>=2.0.0 (from supabase)\n",
            "  Downloading realtime-2.4.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting storage3<0.12,>=0.10 (from supabase)\n",
            "  Downloading storage3-0.11.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting supafunc<0.10,>=0.9 (from supabase)\n",
            "  Downloading supafunc-0.9.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.10 in /usr/local/lib/python3.11/dist-packages (from gotrue<3.0.0,>=2.11.0->supabase) (2.10.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.26->supabase) (0.14.0)\n",
            "Collecting deprecation<3.0.0,>=2.1.0 (from postgrest<0.20,>=0.19->supabase)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.11.13 in /usr/local/lib/python3.11/dist-packages (from realtime<3.0.0,>=2.0.0->supabase) (3.11.13)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from realtime<3.0.0,>=2.0.0->supabase) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from realtime<3.0.0,>=2.0.0->supabase) (4.12.2)\n",
            "Requirement already satisfied: websockets<15,>=11 in /usr/local/lib/python3.11/dist-packages (from realtime<3.0.0,>=2.0.0->supabase) (14.2)\n",
            "Collecting strenum<0.5.0,>=0.4.15 (from supafunc<0.10,>=0.9->supabase)\n",
            "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.13->realtime<3.0.0,>=2.0.0->supabase) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.13->realtime<3.0.0,>=2.0.0->supabase) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.13->realtime<3.0.0,>=2.0.0->supabase) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.13->realtime<3.0.0,>=2.0.0->supabase) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.13->realtime<3.0.0,>=2.0.0->supabase) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.13->realtime<3.0.0,>=2.0.0->supabase) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.13->realtime<3.0.0,>=2.0.0->supabase) (1.18.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from deprecation<3.0.0,>=2.1.0->postgrest<0.20,>=0.19->supabase) (24.2)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.1->realtime<3.0.0,>=2.0.0->supabase) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.26->supabase) (1.3.1)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (4.1.0)\n",
            "Downloading supabase-2.13.0-py3-none-any.whl (17 kB)\n",
            "Downloading gotrue-2.11.4-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading postgrest-0.19.3-py3-none-any.whl (22 kB)\n",
            "Downloading realtime-2.4.1-py3-none-any.whl (22 kB)\n",
            "Downloading storage3-0.11.3-py3-none-any.whl (17 kB)\n",
            "Downloading supafunc-0.9.3-py3-none-any.whl (7.7 kB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
            "Installing collected packages: strenum, deprecation, realtime, supafunc, storage3, postgrest, gotrue, supabase\n",
            "Successfully installed deprecation-2.1.0 gotrue-2.11.4 postgrest-0.19.3 realtime-2.4.1 storage3-0.11.3 strenum-0.4.15 supabase-2.13.0 supafunc-0.9.3\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "P2EnxlyR0ai-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data from the supabase of kilterboard.app\n",
        "# DO NOT RUN unneccessarily\n",
        "\"\"\"\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pandas as pd\n",
        "from supabase import create_client\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Supabase connection details\n",
        "SUPABASE_URL = \"https://drmzubrwofxyzyhicvvx.supabase.co\"\n",
        "SUPABASE_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoiYW5vbiIsImlhdCI6MTYzMTI3NDA1MiwiZXhwIjoxOTQ2ODUwMDUyfQ.vBZ8uBgVI3Wc9RaJ2STinaVnd0dY2HHyK42YkqBxUR0\"\n",
        "\n",
        "# Output directory for the data\n",
        "OUTPUT_DIR = \"kilterboard_data\"\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def initialize_supabase():\n",
        "    \"\"\"Initialize the Supabase client\"\"\"\n",
        "    return create_client(SUPABASE_URL, SUPABASE_KEY)\n",
        "\n",
        "def fetch_all_records(supabase, table_name, page_size=1000):\n",
        "    \"\"\"Fetch all records from a table with pagination\"\"\"\n",
        "    all_records = []\n",
        "    offset = 0\n",
        "    has_more = True\n",
        "\n",
        "    print(f\"Fetching data from '{table_name}' table...\")\n",
        "\n",
        "    while has_more:\n",
        "        try:\n",
        "            response = supabase.table(table_name).select(\"*\").range(offset, offset + page_size - 1).execute()\n",
        "\n",
        "            data = response.data\n",
        "            count = len(data)\n",
        "\n",
        "            if count > 0:\n",
        "                all_records.extend(data)\n",
        "                offset += count\n",
        "                print(f\"  Fetched {len(all_records)} records so far...\")\n",
        "\n",
        "                # If we got fewer records than requested, we're at the end\n",
        "                has_more = count == page_size\n",
        "            else:\n",
        "                has_more = False\n",
        "\n",
        "            # Be nice to the API and avoid rate limiting\n",
        "            time.sleep(0.5)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching data from {table_name}: {e}\")\n",
        "            break\n",
        "\n",
        "    print(f\"Total records fetched from '{table_name}': {len(all_records)}\")\n",
        "    return all_records\n",
        "\n",
        "def discover_tables(supabase):\n",
        "    \"\"\"Try to discover available tables in the database\"\"\"\n",
        "    # Common tables we might expect to find in a climbing app\n",
        "    potential_tables = [\n",
        "        \"climbs\", \"angles\", \"setters\", \"ascents\", \"users\", \"grades\",\n",
        "        \"boards\", \"holds\", \"problems\", \"ratings\", \"comments\", \"favorites\",\n",
        "        \"climb_holds\", \"climb_angles\", \"climb_grades\", \"climb_ratings\"\n",
        "    ]\n",
        "\n",
        "    available_tables = []\n",
        "\n",
        "    print(\"Discovering available tables...\")\n",
        "    for table in tqdm(potential_tables):\n",
        "        try:\n",
        "            response = supabase.table(table).select(\"*\").limit(1).execute()\n",
        "            if response:\n",
        "                available_tables.append(table)\n",
        "                print(f\"  Found table: {table}\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    return available_tables\n",
        "\n",
        "def save_data_to_csv(data, table_name):\n",
        "    \"\"\"Save data to CSV file\"\"\"\n",
        "    if not data:\n",
        "        print(f\"No data to save for table '{table_name}'\")\n",
        "        return\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    file_path = os.path.join(OUTPUT_DIR, f\"{table_name}.csv\")\n",
        "    df.to_csv(file_path, index=False)\n",
        "    print(f\"Saved {len(df)} records to {file_path}\")\n",
        "\n",
        "    # Also save raw JSON for backup\n",
        "    json_path = os.path.join(OUTPUT_DIR, f\"{table_name}.json\")\n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(data, f)\n",
        "\n",
        "def download_all_data():\n",
        "    \"\"\"Main function to download all data\"\"\"\n",
        "    supabase = initialize_supabase()\n",
        "\n",
        "    # First, try to discover available tables\n",
        "    available_tables = discover_tables(supabase)\n",
        "\n",
        "    if not available_tables:\n",
        "        print(\"No tables discovered. Trying known tables...\")\n",
        "        available_tables = [\"climbs\"]  # We know this table exists from the code snippet\n",
        "\n",
        "    # Download data from each available table\n",
        "    for table in available_tables:\n",
        "        data = fetch_all_records(supabase, table)\n",
        "        save_data_to_csv(data, table)\n",
        "\n",
        "    # Additionally, try to get specific climb data with related information\n",
        "    try:\n",
        "        print(\"Attempting to fetch detailed climb information...\")\n",
        "        # This is a more advanced query that might work if the schema allows it\n",
        "        response = supabase.table(\"climbs\").select(\"*, setters(*)\").execute()\n",
        "        if response.data:\n",
        "            save_data_to_csv(response.data, \"climbs_with_setters\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not fetch detailed climb information: {e}\")\n",
        "\n",
        "    print(f\"\\nData download complete! Files saved to '{OUTPUT_DIR}' directory.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting Kilter Board data download...\")\n",
        "    download_all_data()\n",
        "    print(\"Process complete!\")\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEJ6FkCeZW6j",
        "outputId": "fb83c8ff-9862-4385-ce73-41076668e7e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Kilter Board data download...\n",
            "Discovering available tables...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▋         | 1/16 [00:01<00:16,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Found table: climbs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:10<00:00,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching data from 'climbs' table...\n",
            "  Fetched 1000 records so far...\n",
            "  Fetched 2000 records so far...\n",
            "  Fetched 3000 records so far...\n",
            "  Fetched 4000 records so far...\n",
            "  Fetched 5000 records so far...\n",
            "  Fetched 6000 records so far...\n",
            "  Fetched 7000 records so far...\n",
            "  Fetched 8000 records so far...\n",
            "  Fetched 9000 records so far...\n",
            "  Fetched 10000 records so far...\n",
            "  Fetched 11000 records so far...\n",
            "  Fetched 12000 records so far...\n",
            "  Fetched 13000 records so far...\n",
            "  Fetched 14000 records so far...\n",
            "  Fetched 15000 records so far...\n",
            "  Fetched 16000 records so far...\n",
            "  Fetched 17000 records so far...\n",
            "  Fetched 18000 records so far...\n",
            "  Fetched 19000 records so far...\n",
            "  Fetched 20000 records so far...\n",
            "  Fetched 21000 records so far...\n",
            "  Fetched 22000 records so far...\n",
            "  Fetched 22343 records so far...\n",
            "Total records fetched from 'climbs': 22343\n",
            "Saved 22343 records to kilterboard_data/climbs.csv\n",
            "Attempting to fetch detailed climb information...\n",
            "Could not fetch detailed climb information: {'code': 'PGRST200', 'details': \"Searched for a foreign key relationship between 'climbs' and 'setters' in the schema 'public', but no matches were found.\", 'hint': None, 'message': \"Could not find a relationship between 'climbs' and 'setters' in the schema cache\"}\n",
            "\n",
            "Data download complete! Files saved to 'kilterboard_data' directory.\n",
            "Process complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!ls \"/content/drive/My Drive/kilterboard_data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WDV9xj-63jvo",
        "outputId": "df62b643-9b7b-4631-99df-08b45b595d80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "climbs.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "climbs = pd.read_csv(\"/content/drive/My Drive/kilterboard_data/climbs.csv\")\n",
        "print((climbs[0:1].climb_stats.values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KTN4PY6-4KpP",
        "outputId": "fe3c23bb-bc5b-41d8-c34b-3c2267f178db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"[{'angle': 0, 'fa_at': '2019-12-05 16:39:44', 'climb_uuid': 'F01419E12672459396CA62E3655ABC46', 'fa_username': 'sheylo', 'quality_average': 2.68571, 'ascensionist_count': 35, 'difficulty_average': 14.8857}, {'angle': 5, 'fa_at': '2020-06-01 23:37:50', 'climb_uuid': 'F01419E12672459396CA62E3655ABC46', 'fa_username': 'djragan', 'quality_average': 2, 'ascensionist_count': 2, 'difficulty_average': 12}, {'angle': 10, 'fa_at': '2019-10-23 07:48:59', 'climb_uuid': 'F01419E12672459396CA62E3655ABC46', 'fa_username': 'gmorgan', 'quality_average': 2.67669, 'ascensionist_count': 133, 'difficulty_average': 15.8571}, {'angle': 15, 'fa_at': '2019-06-09 21:59:23', 'climb_uuid': 'F01419E12672459396CA62E3655ABC46', 'fa_username': 'tnt5027', 'quality_average': 2.70526, 'ascensionist_count': 190, 'difficulty_average': 15.9526}, {'angle': 20, 'fa_at': '2019-02-05 05:01:37', 'climb_uuid': 'F01419E12672459396CA62E3655ABC46', 'fa_username': 'latrokles', 'quality_average': 2.7341, 'ascensionist_count': 346, 'difficulty_average': 16.1127}, {'angle': 25, 'fa_at': '2019-03-10 18:57:52', 'climb_uuid': 'F01419E12672459396CA62E3655ABC46', 'fa_username': 'TufasBoulderLounge', 'quality_average': 2.73684, 'ascensionist_count': 133, 'difficulty_average': 17.5414}, {'angle': 30, 'fa_at': '2018-12-20 21:13:34', 'climb_uuid': 'F01419E12672459396CA62E3655ABC46', 'fa_username': 'mvnv', 'quality_average': 2.7709, 'ascensionist_count': 1340, 'difficulty_average': 17.7627}, {'angle': 35, 'fa_at': '2019-01-18 04:34:35', 'climb_uuid': 'F01419E12672459396CA62E3655ABC46', 'fa_username': 'ccarrico', 'quality_average': 2.84211, 'ascensionist_count': 304, 'difficulty_average': 18.0855}, {'angle': 40, 'fa_at': '2018-12-06 21:15:24', 'climb_uuid': 'F01419E12672459396CA62E3655ABC46', 'fa_username': 'jwebxl', 'quality_average': 2.80232, 'ascensionist_count': 1123, 'difficulty_average': 18.545}, {'angle': 45, 'fa_at': '2018-12-16 20:43:22', 'climb_uuid': 'F01419E12672459396CA62E3655ABC46', 'fa_username': 'GW_Kilter', 'quality_average': 2.7554, 'ascensionist_count': 973, 'difficulty_average': 19.8571}, {'angle': 50, 'fa_at': '2018-12-11 01:15:13', 'climb_uuid': 'F01419E12672459396CA62E3655ABC46', 'fa_username': 'KevinCuck', 'quality_average': 2.73913, 'ascensionist_count': 92, 'difficulty_average': 18.913}, {'angle': 55, 'fa_at': '2018-12-07 00:16:03', 'climb_uuid': 'F01419E12672459396CA62E3655ABC46', 'fa_username': 'daxxta', 'quality_average': 2.84615, 'ascensionist_count': 52, 'difficulty_average': 20.6346}, {'angle': 60, 'fa_at': '2019-09-18 23:10:57', 'climb_uuid': 'F01419E12672459396CA62E3655ABC46', 'fa_username': 'paulrobinson', 'quality_average': 2.84, 'ascensionist_count': 50, 'difficulty_average': 22}, {'angle': 65, 'fa_at': '2019-12-19 19:31:22', 'climb_uuid': 'F01419E12672459396CA62E3655ABC46', 'fa_username': 'danfost', 'quality_average': 2.5, 'ascensionist_count': 4, 'difficulty_average': 22.25}, {'angle': 70, 'fa_at': '2020-01-07 09:21:01', 'climb_uuid': 'F01419E12672459396CA62E3655ABC46', 'fa_username': 'Dean177', 'quality_average': 2, 'ascensionist_count': 1, 'difficulty_average': 17}]\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import ast\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Define the improved conversion between difficulty_average and V-grades\n",
        "def difficulty_to_vgrade(difficulty):\n",
        "    \"\"\"Convert Kilter Board difficulty_average to V-grade with a more refined scale\"\"\"\n",
        "    if difficulty is None or pd.isna(difficulty):\n",
        "        return \"N/A\"\n",
        "\n",
        "    # More detailed and precise conversion\n",
        "    if difficulty < 8:\n",
        "        return \"VB\"\n",
        "    elif difficulty < 10:\n",
        "        return \"V0\"\n",
        "    elif difficulty < 12:\n",
        "        return \"V1\"\n",
        "    elif difficulty < 14:\n",
        "        return \"V2\"\n",
        "    elif difficulty < 16:\n",
        "        return \"V3\"\n",
        "    elif difficulty < 18:\n",
        "        return \"V4\"\n",
        "    elif difficulty < 20:\n",
        "        return \"V5\"\n",
        "    elif difficulty < 22:\n",
        "        return \"V6\"\n",
        "    elif difficulty < 24:\n",
        "        return \"V7\"\n",
        "    elif difficulty < 26:\n",
        "        return \"V8\"\n",
        "    elif difficulty < 28:\n",
        "        return \"V9\"\n",
        "    elif difficulty < 30:\n",
        "        return \"V10\"\n",
        "    elif difficulty < 32:\n",
        "        return \"V11\"\n",
        "    elif difficulty < 34:\n",
        "        return \"V12\"\n",
        "    elif difficulty < 36:\n",
        "        return \"V13\"\n",
        "    elif difficulty < 38:\n",
        "        return \"V14\"\n",
        "    elif difficulty < 40:\n",
        "        return \"V15\"\n",
        "    else:\n",
        "        return \"V16+\"\n",
        "\n",
        "def parse_climb_stats(stats_str):\n",
        "    \"\"\"Parse the climb_stats string into a list of dictionaries\"\"\"\n",
        "    if not isinstance(stats_str, str):\n",
        "        return []\n",
        "\n",
        "    # Clean the string if it's wrapped in quotes and brackets\n",
        "    if stats_str.startswith('[\"[') and stats_str.endswith(']\"]'):\n",
        "        stats_str = stats_str[3:-3]  # Remove the [\"[ and ]\"]\n",
        "\n",
        "    try:\n",
        "        # Try parsing as a list of dictionaries\n",
        "        return ast.literal_eval(stats_str)\n",
        "    except (SyntaxError, ValueError):\n",
        "        print(f\"Error parsing: {stats_str[:100]}...\")\n",
        "        return []\n",
        "\n",
        "def find_setup_by_angle(climb_stats, target_angle):\n",
        "    \"\"\"Find the setup for a specific angle\"\"\"\n",
        "    stats_list = parse_climb_stats(climb_stats)\n",
        "\n",
        "    for stats in stats_list:\n",
        "        if stats.get('angle') == target_angle:\n",
        "            return stats\n",
        "\n",
        "    return None\n",
        "\n",
        "def find_most_popular_setup(climb_stats):\n",
        "    \"\"\"Find the angle with the most ascents\"\"\"\n",
        "    stats_list = parse_climb_stats(climb_stats)\n",
        "\n",
        "    most_ascents = 0\n",
        "    popular_setup = None\n",
        "\n",
        "    for stats in stats_list:\n",
        "        ascents = stats.get('ascensionist_count', 0)\n",
        "        if ascents > most_ascents:\n",
        "            most_ascents = ascents\n",
        "            popular_setup = stats\n",
        "\n",
        "    return popular_setup\n",
        "\n",
        "def pretty_print_climbs(data, num_entries=20):\n",
        "    \"\"\"Load climb data and pretty print with V-grades\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    data : str or pandas.DataFrame\n",
        "        Either a file path (CSV or JSON) or a pandas DataFrame containing the climb data\n",
        "    num_entries : int, optional\n",
        "        Number of entries to display (default: 20)\n",
        "    \"\"\"\n",
        "    # First check if data is a DataFrame\n",
        "    if isinstance(data, pd.DataFrame):\n",
        "        df = data\n",
        "    # Otherwise, try to load data from a file path\n",
        "    elif isinstance(data, str):\n",
        "        if data.endswith('.csv'):\n",
        "            df = pd.read_csv(data)\n",
        "        elif data.endswith('.json'):\n",
        "            with open(data, 'r') as f:\n",
        "                json_data = json.load(f)\n",
        "            df = pd.DataFrame(json_data)\n",
        "        else:\n",
        "            print(\"Unsupported file format. Please use CSV or JSON.\")\n",
        "            return\n",
        "    else:\n",
        "        print(\"Unsupported data type. Please provide a file path or pandas DataFrame.\")\n",
        "        return\n",
        "\n",
        "    # Create display data\n",
        "    display_data = []\n",
        "\n",
        "    for _, row in df.head(num_entries).iterrows():\n",
        "        name = row.get('name', 'Unnamed')\n",
        "        setter = row.get('setter_username', 'Unknown')\n",
        "        total_ascents = row.get('total_ascents', 0)\n",
        "\n",
        "        # Find the most popular setup\n",
        "        popular_setup = find_most_popular_setup(row.get('climb_stats', []))\n",
        "\n",
        "        if popular_setup:\n",
        "            angle = popular_setup.get('angle', 'N/A')\n",
        "            difficulty = popular_setup.get('difficulty_average')\n",
        "            vgrade = difficulty_to_vgrade(difficulty)\n",
        "            ascensionist_count = popular_setup.get('ascensionist_count', 0)\n",
        "            quality = popular_setup.get('quality_average', 'N/A')\n",
        "            fa_username = popular_setup.get('fa_username', 'Unknown')\n",
        "\n",
        "            display_data.append([\n",
        "                name,\n",
        "                setter,\n",
        "                vgrade,\n",
        "                # Display raw difficulty value for reference\n",
        "         #       f\"{difficulty:.1f}\" if difficulty else 'N/A',\n",
        "                angle,\n",
        "                ascensionist_count,\n",
        "                total_ascents,\n",
        "                f\"{quality:.1f}\" if quality else 'N/A',\n",
        "                fa_username\n",
        "            ])\n",
        "        else:\n",
        "            display_data.append([name, setter, 'N/A', 'N/A', 'N/A', 0, total_ascents, 'N/A', 'N/A'])\n",
        "\n",
        "    # Print as a nice table\n",
        "    headers = [\n",
        "        \"Climb Name\",\n",
        "        \"Setter\",\n",
        "        \"V-Grade\",\n",
        "     #   \"Raw Difficulty\",\n",
        "        \"Angle°\",\n",
        "        \"Setup Ascents\",\n",
        "        \"Total Ascents\",\n",
        "        \"Rating\",\n",
        "        \"FA by\"\n",
        "    ]\n",
        "    print(\"\\n\" + tabulate(display_data, headers=headers, tablefmt=\"fancy_grid\"))\n",
        "\n",
        "    # Print explanation\n",
        "    print(\"\\nGrade Conversion Information:\")\n",
        "    print(\"The V-grades are converted from Kilterboard 'difficulty_average' (0-40) using the following scale:\")\n",
        "    print(\"VB: < 8\")\n",
        "    print(\"V0: 8-10, V1: 10-12, V2: 12-14, V3: 14-16, V4: 16-18, V5: 18-20\")\n",
        "    print(\"V6: 20-22, V7: 22-24, V8: 24-26, V9: 26-28, V10: 28-30\")\n",
        "    print(\"V11: 30-32, V12: 32-34, V13: 34-36, V14: 36-38, V15: 38-40, V16+: > 40\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NuS4Pl2A1pfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretty_print_climbs(climbs, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMJutVLS3hEW",
        "outputId": "b2de7540-092a-49b5-bea6-9a59e167ac89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "╒══════════════════════════════════╤══════════════╤═══════════╤══════════╤═════════════════╤═════════════════╤══════════╤═════════════╕\n",
            "│ Climb Name                       │ Setter       │ V-Grade   │   Angle° │   Setup Ascents │   Total Ascents │   Rating │ FA by       │\n",
            "╞══════════════════════════════════╪══════════════╪═══════════╪══════════╪═════════════════╪═════════════════╪══════════╪═════════════╡\n",
            "│ swooped                          │ jwebxl       │ V4        │       30 │            1340 │            4778 │      2.8 │ mvnv        │\n",
            "├──────────────────────────────────┼──────────────┼───────────┼──────────┼─────────────────┼─────────────────┼──────────┼─────────────┤\n",
            "│ Floats Your Boat                 │ will_avelar  │ V2        │       40 │            1547 │            4593 │      2.7 │ will_avelar │\n",
            "├──────────────────────────────────┼──────────────┼───────────┼──────────┼─────────────────┼─────────────────┼──────────┼─────────────┤\n",
            "│ Lack of Faith                    │ KilterStudio │ V4        │       45 │            1092 │            3200 │      2.7 │ KevinCuck   │\n",
            "├──────────────────────────────────┼──────────────┼───────────┼──────────┼─────────────────┼─────────────────┼──────────┼─────────────┤\n",
            "│ proj braj                        │ jwebxl       │ V5        │       30 │             841 │            2656 │      2.8 │ s14rob      │\n",
            "├──────────────────────────────────┼──────────────┼───────────┼──────────┼─────────────────┼─────────────────┼──────────┼─────────────┤\n",
            "│ Sour Gummi Worms                 │ martiiiin    │ V3        │       40 │             769 │            2655 │      2.7 │ will_avelar │\n",
            "├──────────────────────────────────┼──────────────┼───────────┼──────────┼─────────────────┼─────────────────┼──────────┼─────────────┤\n",
            "│ Gabe rules and so do the spiders │ dperez       │ V4        │        0 │               7 │               7 │      2.1 │ dperez      │\n",
            "├──────────────────────────────────┼──────────────┼───────────┼──────────┼─────────────────┼─────────────────┼──────────┼─────────────┤\n",
            "│ HilDawgyDawg                     │ BKBChicago   │ V4        │       40 │             912 │            2508 │      2.7 │ BKBChicago  │\n",
            "├──────────────────────────────────┼──────────────┼───────────┼──────────┼─────────────────┼─────────────────┼──────────┼─────────────┤\n",
            "│ warm meh 2                       │ KilterStudio │ V2        │       30 │             906 │            2207 │      2.7 │ BKBChicago  │\n",
            "├──────────────────────────────────┼──────────────┼───────────┼──────────┼─────────────────┼─────────────────┼──────────┼─────────────┤\n",
            "│ Tumble Weed                      │ s14rob       │ V2        │       30 │            1147 │            2104 │      2.6 │ s14rob      │\n",
            "├──────────────────────────────────┼──────────────┼───────────┼──────────┼─────────────────┼─────────────────┼──────────┼─────────────┤\n",
            "│ Everbody Knows Your Name         │ jwilder      │ V4        │       30 │            1196 │            2104 │      2.7 │ jwilder     │\n",
            "╘══════════════════════════════════╧══════════════╧═══════════╧══════════╧═════════════════╧═════════════════╧══════════╧═════════════╛\n",
            "\n",
            "Grade Conversion Information:\n",
            "The V-grades are converted from Kilterboard 'difficulty_average' (0-40) using the following scale:\n",
            "VB: < 8\n",
            "V0: 8-10, V1: 10-12, V2: 12-14, V3: 14-16, V4: 16-18, V5: 18-20\n",
            "V6: 20-22, V7: 22-24, V8: 24-26, V9: 26-28, V10: 28-30\n",
            "V11: 30-32, V12: 32-34, V13: 34-36, V14: 36-38, V15: 38-40, V16+: > 40\n"
          ]
        }
      ]
    }
  ]
}